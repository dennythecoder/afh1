<?xml version='1.0' encoding='utf-8'?>
<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta name="Generator" content="Microsoft Word 15 (filtered)"/>
    <title>Unknown</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  <link href="stylesheet.css" rel="stylesheet" type="text/css"/>
<link href="page_styles.css" rel="stylesheet" type="text/css"/>
</head>
  <body lang="EN-US" class="calibre">

<div class="wordsection">

<p class="msonormal"><b class="calibre1">Chapter 23 </b></p>

<p class="msonormal1"><b class="calibre1">CRITICAL THINKING AND DECISION-MAKING </b></p>

<p class="msonormal2"><b class="calibre1"><i class="calibre2">Section
23A—Overview  </i></b></p>

<p class="msonormal3"><b class="calibre1">23.1. Introduction: </b></p>

<p class="msonormal4">23.1.1. Effective Airmanship requires good decision-making.
From Airman Basic to General the decisions each of us make every day impact the
delivery of airpower. The following chapter is designed to spur development of
critical thinking habits in our Airmen and deepen their awareness of the
decision-making processes. The habits of mind necessary to become a critical
thinker are developed over time; there is no magical process or checklist to
follow. Each of us must work every day to make good decisions by consciously
applying the intellectual analysis necessary to account for complexities not
normally considered and often overlooked. </p>

<p class="msonormal5"><i class="calibre2">The process of
decision-making is as important as the information analyzed. The trap many of
us fall into is focusing on the decision, not how the decision should be made.</i><b class="calibre1">
</b></p>

<p class="msonormal6">23.1.2. Decisions are made by individuals acting alone, in
groups, or on behalf of organizations, each of these levels of decision-making
present a variety of challenges. The following discussion is intended to
highlight these challenges and make you aware of the conscious and unconscious
challenges to applying good habits of mind (critical thought) as Airmen every
day. </p>

<p class="msonormal7"><b class="calibre1"><i class="calibre2">Section
23B—Critical Thinking and Human Nature </i></b></p>

<p class="msonormal3"><b class="calibre1">23.2. Cognitive Bias: </b></p>

<p class="msonormal8">23.2.1. In thinking about problems we are seldom the
perfectly rational actor we hope to be. Instead we are influenced by a number
of factors that shape how we interpret information, weigh its relevance, and
ultimately decide upon a course of action or inaction as the situation
dictates. Psychologists use the term <i class="calibre2">bounded rationality</i> to describe the
actual operating state of the human mind. What this means is that we are unable
to be comprehensive in our gathering and analysis of information as
decision-making models assume. Instead of being truly rational, and making the
best possible decision, we end up ‘<i class="calibre2">satisficing.</i>’ </p>

<p class="msonormal4">23.2.2. Cognitive bias in our decision processes result in
several ‘traps’ decision-makers need to guard against. Some of the more common
are: </p>

<p class="msonormal9">23.2.2.1.<b class="calibre1"> Overconfidence bias.</b> Humans are
overconfident in their own judgments, often unreasonably so. </p>

<p class="msonormal9">23.2.2.2.<b class="calibre1"> Sunk-cost effect. </b>The tendency to escalate
commitment to a course of action you have already made a substantial investment
or resources in (time, money, personnel, etc.) despite poor performance. </p>

<p class="msonormal9">23.2.2.3.<b class="calibre1"> Availability bias. </b>Tendency to place too
much emphasis on information we have available instead of the information we
need during decision-making. </p>

<p class="msonormal9">23.2.2.4.<b class="calibre1"> Confirmation bias. </b>The most prevalent
bias, this propensity refers to our tendency to gather and use information that
confirms our existing views while downplaying or avoiding information that
challenges our working hypothesis. </p>

<p class="msonormal9">23.2.2.5.<b class="calibre1"> Anchoring bias.</b> The unconscious tendency
to allow an initial reference point to distort our estimates, even when that
initial reference point is completely arbitrary. Starting at an extreme
position may act as an anchor for all parties in a decision process or
negotiation. In a negotiation, this bias can work in favor of the side that
stakes out the initial reference point—both sides tend to use the initial
position as a reference point for the solution (i.e. car salesman techniques). </p>

<p class="msonormal9">23.2.2.6.<b class="calibre1"> Illusory bias.</b> Tendency to jump to
conclusions about the relationship between two variables when in fact no
relationship (correlation) exists. </p>

<p class="msonormal9">23.2.2.7.<b class="calibre1"> Hindsight bias.</b> The tendency to judge past
events as easily predictable when in fact they were not easily foreseen. This
bias limits our ability to learn from past mistakes and may affect how leaders
evaluate subordinate decision-making. </p>

<p class="msonormal9">23.2.2.8.<b class="calibre1"> Egocentrism.</b> When we attribute more credit
to ourselves for group or collaborative outcome than an outside party making an
unbiased assessment would. </p>

<p class="msonormal10"> </p>

<p class="msonormal4">23.2.3.<b class="calibre1"> </b>As decision makers Airmen need to be aware of
cognitive biases and consciously take steps to guard against their affects. The
habitual application of critical thinking methods to the gathering and analysis
of information helps reduce our unconscious and natural tendency to satisfice
in decision-making. Some techniques to counter cognitive biases include: </p>

<p class="msonormal9">23.2.3.1.<b class="calibre1"> After-action reviews</b> provide powerful
learning moments for participants and serve as a forum for feedback to the
decision maker about his/her decision style – helping to prevent repetition of
mistakes. </p>

<p class="msonormal9">23.2.3.2.<b class="calibre1"> Seeking unbiased outside expert input</b> can
help provide a check and balance on reasoning and the interpretation of
available information.  </p>

<p class="msonormal9">23.2.3.3.<b class="calibre1"> Creating a decision environment encouraging
candid dialogue</b> and vigorous debate is perhaps the most effective way to
minimize the influence of cognitive bias. </p>

<p class="msonormal3"><b class="calibre1">23.3. Mental Frames: </b></p>

<p class="msonormal4">23.3.1. Each of us uses mental frameworks and shortcuts to
simplify our understanding of a complex world. The use of these frameworks
helps us process information quickly and efficiently. Understanding that these
frameworks contribute to the bias presented earlier, the following discussion
is intended to make you aware of how the frameworks you have built, based on your
own unique personal experiences; these experiences shape your own
decision-making process and the solutions you derive.<b class="calibre1"> </b></p>

<p class="msonormal4">23.3.2. Frames consist of our assumptions about how things
are related and how they work. How we frame a problem influences the decisions
we make. This effect is particularly noticeable when framing a challenge as
either a risk or an opportunity. Research shows that the human mind estimates
the expected return when confronted with a risky situation and that we tend to
be risk adverse. Our risk aversion and the importance of framing are explained
in Prospect Theory. </p>

<p class="msonormal3"><b class="calibre1">23.4. Prospect Theory. </b></p>

<p class="msonormal4">According to the <i class="calibre2">Prospect Theory,</i> framing a situation
as a potential gain causes decision makers to act differently than framing same
situation as a potential loss. Faced with potential losses most people are
willing to take greater risks than when facing with potential gains. The Prospect
Theory helps explain our tendency to escalate commitment based on sunk costs
instead of making rational evaluations based on how things exist today. Based
on sunk cost arguments, leaders often take-on more and more risk, committing
additional resources in order to avoid losses even when the chances of success
are low. </p>

<p class="msonormal3"><b class="calibre1">23.5. Risk or Opportunity. </b></p>

<p class="msonormal4">Another implication of framing is how organizations react
when faced with changes in the operating environment or mission tasking. At the
organizational level, threats to our comfortable framework of assumptions are
often met with rigid resistance while changes we see as opportunities are met
with flexible and adaptable approaches. Often inaccurate expectations are
established as a result of mental frames applied by decision makers. As human
beings Airmen are subject to the initial frameworks we establish when
confronting change. For good or bad these frameworks act to limit the
information we take in, our willingness to fairly and unbiasedly assess
information, and ultimately restrict the solution sets we create. </p>

<p class="msonormal3"><b class="calibre1">23.6. Intuition: </b></p>

<p class="msonormal4">23.6.1. When decision makers use intuition to choose courses
of action they are not evaluating a whole series of alternatives and are not
selecting solutions based on objective analysis. Intuition is based on previous
experience, and matching patterns from these experiences, to cues picked up in
the current environment. As patterns are recognized, humans automatically
reason by analogy, projecting past situations into our current environment.
Based on recognition of patterns, decision makers often select a course of
action as if reading a script, instead of exploring a wide range of options.
Having decided on an initial preferred course of action, senior leaders often
mentally play out the solution; and if it seems feasible, they go with it. For
decision makers, intuition is both a powerful guide and a potential decision
trap. </p>

<p class="msonormal4">23.6.2. When operating in challenging or ambiguous
situations, highly experienced professionals often have intuitive reactions to
events. Although unable to articulate their unconscious pattern recognition,
experts are often correct in their analysis and selection of a course of action
despite what a novice may perceive as a lack of information or signals pointing
to a contrary course of action. In highly complex and ambiguous situations,
however, the complexity obscures pattern recognition and experienced Airmen can
mistakenly apply incorrect or outdated models, resulting in poor
decision-making. This is especially true when decision makers are operating
outside of their experience base, for instance, when leading higher-level
organizations or moving from one career field to another. </p>

<p class="msonormal10"> </p>

<p class="msonormal3"><b class="calibre1">23.7. Key Points to Remember:</b> </p>

<p class="msonormal4">23.7.1. Airmen, especially leaders within any organization,
must be careful about imposing mental frames on themselves and their team in
order to create an environment where critical thinking is exercised. When
leaders hold back personal opinions they avoid framing the situation in
preconceived ways (that constricts the range of advice and alternatives
offered). By consciously avoiding the natural tendency to view change as
threatening, intentionally framing change as an opportunity, Airmen are free to
exercise the habits of mind necessary to make well informed decisions. </p>

<p class="msonormal4">23.7.2. A challenge for Airmen in a position of
responsibility is to avoid the human tendency to continue a course of action
due to sunk costs; proper use of combined intuitive judgment and formal
analysis is one means for avoiding this decision trap. The use of analysis to
check intuition is an effective decision-making technique. Formal analysis can
check intuition and assures you challenge your intuitive judgment, not confirm
it. Conversely, intuition is useful in validating and testing the assumptions
that underlie analysis. As Airmen, recognizing the value of intuition is just
as critical as guarding against a lack of analysis in the decision-making
process. Do not try to replace intuition with rules and procedures; intuition
is often compressed experience indicating as of yet unrecognized patterns in
the environment. Airmen must routinely and consciously create decision
processes with information flowing freely in both directions. </p>

<p class="msonormal11">23.7.3. A simple five-step process for communicating intuitive
decisions, seeking feedback, and conveying intent is to use the following
statements when addressing decision teams: </p>

<p class="msonormal12">23.7.3.1. Here’s what I think we face. </p>

<p class="msonormal12">23.7.3.2. Here’s what I think we should do. </p>

<p class="msonormal12">23.7.3.3. Here’s why. </p>

<p class="msonormal9">23.7.3.4. Here’s what we should keep our eye on. </p>

<p class="msonormal9">23.7.3.5. Now, talk to me.<b class="calibre1"> </b></p>

<p class="msonormal3"><b class="calibre1">23.8. Analogies: </b></p>

<p class="msonormal13">23.8.1. Analogies are very powerful decision-making tools and
often the greatest innovative breakthroughs occur when analogies from one field
or domain are applied to others. Reasoning by analogy occurs when we assess a
situation and match it to similar experiences we have encountered, assuming
that they are alike. At the conscious level, Airmen can deliberately use
analogies to frame a decision-making process; they save time and provide clues
about possible courses of action and implications, at the unconscious level
analogies play a large role in intuition as discussed in the previous section. </p>

<p class="msonormal4">23.8.2. The critical thinking trap inherent in the use of
analogies is that they can lead us to focus on similarities between events and
downplay important differences. Very powerful experiences from our past leave
us overly reliant on very salient analogies, even when they no longer fit
current situation; thus, blinding Airmen to the requirement to explore and
question underlying assumptions. </p>

<p class="msonormal14">23.8.3. In order to avoid the temptation to focus on
similarities and downplay differences decision makers and their teams should
consciously make two lists: one describing similarities and the other
describing differences. A second technique is to write down and clearly define
what you know, what is unknown, and what you presume about the situation you
are analyzing. The objective of both these techniques is to clearly separate
fact from assumption and then probe your presumptions carefully. The act of
questioning our assumptions in any decision process is, at its heart, how we
apply the habits of mind necessary for good critical thought. </p>

<p class="msonormal7"><b class="calibre1"><i class="calibre2">Section
23C—Critical Thinking in Groups</i> </b></p>

<p class="msonormal3"><b class="calibre1">23.9. Wisdom of Groups: </b></p>

<p class="msonormal4">23.9.1. Conventional wisdom holds that groups make better
decisions than individuals because they draw from a diverse base of talent and
experience. Unfortunately, many groups fail to make good decisions because they
fail to merge the diverse ideas and recognize potential synergies; the result
is a failure to capitalize on the team’s diverse talents. When this happens
teams can actually make worse decisions than a talented individual. Airmen must
be conscious of how group decisions are made and create teams capable of
applying critical thought to problems in a group setting. </p>

<p class="msonormal4">23.9.2. Airmen engaged in the group decision-making must
consciously structure the process to encourage critical thinking. Leaders must
begin by deciding: </p>

<p class="msonormal9">23.9.2.1. Who should be involved in the decision process? </p>

<p class="msonormal9">23.9.2.2. In what sort of environment does the decision
take place? </p>

<p class="msonormal9">23.9.2.3. How will the participants communicate? </p>

<p class="msonormal9">29.9.2.4. How will the leader control the decision process?
</p>

<p class="msonormal4">23.9.3. Unfortunately, due to bias, a lack of time, framing,
personnel shortages, outside pressure, or any number of other reasons leaders
often fail to decide ‘how to decide?’ Instead, they rely on existing decision
processes and groups, even though they may be unreliable given the context of
the issue. </p>

<p class="msonormal15">23.9.4.
Some argue that groups are more intelligent than individual experts because the
aggregation of their judgment leads to a better answer, even though they are
not a group of experts. In some cases this is true, but it is not a given. </p>

<p class="msonormal4">Several critical preconditions are necessary. To be
effective groups of non-experts must: </p>

<p class="msonormal9">23.9.4.1. Be diverse. </p>

<p class="msonormal9">23.9.4.2. Represent many different disciplines,
perspectives, and areas of expertise. </p>

<p class="msonormal9">23.9.4.3. Be decentralized. </p>

<p class="msonormal9">23.9.4.4. Be able to effectively aggregate all the
individual judgments. </p>

<p class="msonormal9">23.9.4.5. Contain members who are independent (most
important). </p>

<p class="msonormal4">23.9.5. Within groups, information-processing problems can
prevent the pooling of collective knowledge. Group members tend to discuss
areas of common information while failing to surface privately held information
for personal reasons or a failure to recognize its importance. Airmen, because
of our shared heritage and commitment to teamwork must constantly guard against
the trap of ignoring information in an effort to find common ground. Even when
data is widely discussed and analyzed, the filtering of data as it moves up the
decision chain can prevent decision makers from having access to the nuances of
these discussions during the decision process. If as an Airmen you are in
positions to make decisions based on the recommendations of groups you should
be aware of how the group was set-up and operated and make an effort to
understand the decision-making process they used. </p>

<p class="msonormal16">23.9.6.<b class="calibre1"> Wisdom of Groups Conclusion.</b> </p>

<p class="msonormal9">Things to be aware of when forming a decision-making team: </p>

<p class="msonormal9">23.9.6.1. Individuals must be able to sway others in the
crowd, a condition that is often lacking in the organizational decision-making
environment. </p>

<p class="msonormal9">23.9.6.2. Interdependence and hierarchy of group members
can neutralize the benefits group decisions. </p>

<p class="msonormal9">23.9.6.3. Pressure to conform and fractionalization of
groups into sub groups can prevent honest analysis. </p>

<p class="msonormal17">23.9.6.4. The tendency of some individuals to dominate the
discussions can inhibit less aggressive members from presenting their ideas,
especially if these ideas are call into question the prevailing wisdom of the
dominant personalities. </p>

<p class="msonormal9">23.9.6.5. Conversely, members that do not feel personally
accountable for the group’s outcomes may ‘free ride’ by not presenting their
ideas, content to allow others to ‘carry the load’. </p>

<p class="msonormal7"><b class="calibre1">23.10.<i class="calibre2"> Groupthink
(Thinking or Conforming): </i></b></p>

<p class="msonormal4">23.10.1.<i class="calibre2"> Groupthink</i> is a well-known decision trap
most of us are familiar with—and a major reason groups make flawed decisions. <i class="calibre2">Groupthink</i>
occurs when tremendous pressures within the team for conformity and a desire
for unanimity drive decision-making at the expense of true critical thinking.
Without candid dialogue between team members, and real assessment of options,
groups tend to spend most of their time tweaking proposed solutions rather than
examining evidence and assumptions to create new options. Many factors
contribute to groupthink, including the homogeneity of the group, reporting and
supervisory chains, and permanent versus long-term nature of the groups involved.
</p>

<p class="msonormal4">23.10.2. Within groups, especially long standing groups,
individuals often self-sensor based on a desire to avoid becoming ostracized
and marginalized. As a result, a fallacy develops within the team; each member
erroneously believes the other team members unanimously support a decision or
course of action, making it harder to present dissenting opinions. If
alternative options were previously examined and dismissed, they are rarely
reconsidered based on new information or changes in the decision environment. </p>

<p class="msonormal4">23.10.3. To avoid group think Airmen must be aware of the
below symptoms of <i class="calibre2">Groupthink</i>: </p>

<p class="msonormal9">23.10.3.1. The group has a feeling of being invulnerable
(it cannot fail). </p>

<p class="msonormal9">23.10.3.2. Inherent belief that the group is better than
rivals (cultural egocentric thought, stereotyping). </p>

<p class="msonormal9">23.10.3.3. Rationalization away of disconfirming data and
warning signs. </p>

<p class="msonormal9">23.10.3.4. The group has a feeling of being unanimous in
support for particular views. </p>

<p class="msonormal9">23.10.3.5. Majority pressuring those with dissenting views.
</p>

<p class="msonormal9">23.10.3.6. Group member’s self-sensor rather than challenge
majority perspective to avoid becoming ostracized or marginalized. </p>

<p class="msonormal3"><b class="calibre1">23.11. Groupthink Conclusion:</b> </p>

<p class="msonormal4">23.11.1. For some decision events, outside consultation may
be the only way to avoid groupthink. In other cases, Airmen can work to
minimize structural barriers to candid dialogue and reduce groupthink
tendencies within their organization. </p>

<p class="msonormal9">23.11.1.1. Reduce structural complexity and the information
filtering that occurs because of internal organizational barrier and interest
groups. </p>

<p class="msonormal9">23.11.1.2. Defining roles within decision-making teams,
giving responsibility to members for aspects of the analysis process and
holding them accountable for representing these perspectives within the group. </p>

<p class="msonormal9">23.11.1.3. Reducing homogeneity of team composition to
bring in alternative perspectives. </p>

<p class="msonormal9">23.11.1.4. Reduce status difference and rating chain
conflicts between team members that might squelch candid dialogue. </p>

<p class="msonormal9">23.11.1.5. Invite disagreement during the analysis process;
a failure to do so will squelch candid dialogue. </p>

<p class="msonormal3"><b class="calibre1">23.12. Debate and Conflict: </b></p>

<p class="msonormal4">23.12.1. Disagreement between participants in any decision
process is necessary to stimulate inquiry and analysis. The challenge for
leaders in any decision process is to create constructive conflict while
retaining the teamwork and relationships necessary for future decision events.
In the decision-making process, debate focused on the issues and ideas at hand
(<i class="calibre2">cognitive conflict</i>) is constructive; on the other hand, emotional and
personal outbursts (<i class="calibre2">affective conflict</i>) are not. </p>

<p class="msonormal4">23.12.2. A key aspect of managing the decision process is to
stimulate <i class="calibre2">cognitive conflict</i> to advocate positions and analysis—debating
concepts, but not attacking the person representing them. Airmen in leadership
positions should clearly establish ground rules for interaction during
deliberations and require participants to respect each other’s cognitive and
analytical styles. </p>

<p class="msonormal3"><b class="calibre1">23.13. Critical Thinking in Groups Conclusion:</b> </p>

<p class="msonormal4">23.13.1. Decision makers must ensure they are not
structuring their decision process to minimize conflict at the expense of
critical thinking. Leaders set the example by: identifying and articulating the
mental models they apply, encouraging others to challenge these models, avoiding
prematurely selecting courses of action before debate is finished, and
encouraging others to make mistakes. In other words, professional debate is
constructive, unprofessional personalization of debate is not. Without adhering
to the levels of professionalism expected of Airmen we squelch the critical
thinking necessary to innovate and ensure good decision-making. </p>

<p class="msonormal18">23.13.2. Some techniques include assigning members to act as
adversaries; and/or to advocate multiple scenarios address the problem. These
techniques give participants the responsibility to provide contrary
perspectives and use varying lenses for information analysis. Dissenters must
be encouraged to try to persuade other team members, not senior leadership;
this practice stimulates debate and forces critical thinking. However, if
employed, senior leaders must guard against the temptation to domesticate
dissenters, using them as token “devils advocates.” </p>

<p class="msonormal7"><b class="calibre1"><i class="calibre2">Section
23D—Critical Thinking and Organizational Culture</i> </b></p>

<p class="msonormal3"><b class="calibre1">23.14. The Inability to Decide. </b></p>

<p class="msonormal4">Many leaders and organizations are plagued by chronic and
persistent indecision. Indecision resulting from dysfunctional patterns of
behavior manifests itself as one of three harmful organizational cultures: (1)
culture of ‘no’; (2) culture of ‘yes’; and 3) culture of ‘maybe.’ </p>

<p class="msonormal4">23.14.1.<b class="calibre1"> Culture of no</b>. Organizations with a culture
of no have established a decision process where lone dissenters are able to
issue non-concurs within the planning process, effectively blocking overall
organizational goals because they conflict with internal sub-organizational
interests. This culture can arise in organizations where decision meetings
focus on dissections of proposals instead of true debate and analysis. Leaders
who reward subordinates based on their ability to dissect others ideas without
providing alternative courses of action enable and promote a culture of no. Do
not forget the importance of being able to differentiate between the use of a
“devil’s advocate” and the culture of no. In a culture of no, dissenters are
trying to tear down or block proposals and ideas, not critique a proposal with
the intent of strengthening it. </p>

<p class="msonormal4">23.14.2.<b class="calibre1"> Culture of yes.</b> Within a culture of yes,
dissenters tend to stay silent. This silence becomes a tacit endorsement of the
proposal without the benefit of analysis and debate. In this form of
organizational culture, once a decision is made subordinates later express
disagreement to distance themselves from a decision or work to overturn or
undermine the implementation of the plan. Airmen operating in this type of
culture must understand that silence does not mean assent and watch for those
not contributing to the discussion. This type of culture can develop when
leadership devalues critical analysis. Overcoming this cultural tendency requires
leadership to create constructive conflict within the decision process to
surface and analyze concerns and alternative interpretations of evidence. </p>

<p class="msonormal4">23.14.3.<b class="calibre1"> Culture of maybe.</b> Under the culture of
maybe, decision makers work to gather as much information as possible, so much
so they become trapped in “<i class="calibre2">analysis paralysis</i>.” Under <i class="calibre2">analysis
paralysis</i>, decision makers constantly delay action because they think more
information and analysis will clarify their choice. This culture tends to
develop in organizations facing highly ambiguous situations; or in
organizations where competing sections/leaders practice conflict avoidances as
opposed to open analysis and debate. In these organizations, decision makers
must balance the benefit of gaining more information against the diminishing
returns they provide (as opposed to initiating action). While leaders are
seldom able to accurately calculate the cost versus benefit of waiting for
additional clarity, intuitive judgment serves as a cut-off for unnecessary
delay. </p>

<p class="msonormal16">23.14.4.<b class="calibre1"> Procedural Justice: </b></p>

<p class="msonormal9">23.14.4.1. The process by which a decision is made
significantly influences implementation and follow-through of the solution. The
key aspect to outcome of a critical decision is consensus among the team
responsible for enactment. Consensus does not mean unanimity—rather, consensus
is a commitment to, and shared understanding of, the desired outcome. </p>

<p class="msonormal9">23.14.4.2. Sections above discussed the need for debate and
conflict in applying true critical thinking to decisions—and the challenge of
keeping the debate constructive. Airmen must also work to make sure the process
is fair and legitimate. Even when participants agree with the chosen course of
action, if they do not see the process as legitimate they are often
disenchanted with the outcome. Procedural fairness provides support to decision
makers, especially when they are making unpopular decisions. </p>

<p class="msonormal9">23.14.4.3. Fair processes helps build consensus. More
importantly, they aid implementation because participants feel that all perspectives
have been considered and analyzed. If decision-makers are subjective in their
analysis, participants lose faith in the decision process, making it difficult
to support the outcome. Providing participants with time and venues to air
positions, and a transparent system of weighing different perspectives, is
important. In essence, fair process means that the decision maker demonstrates
genuine consideration of alternatives. This does not mean debate continues
endlessly. When final decisions are made the fairness of the process is what
allows Airmen arguing for various positions to rally around the designated way
ahead with confidence that the decision maker considered all aspects before
making the decision on which course of action to pursue. </p>

<p class="msonormal9">23.14.4.4. Procedural legitimacy in decision-making occurs
when the decision process is perceived to be in line with an organization’s
socially accepted norms and desired behavior. Airmen in leadership positions
must avoid artificially limiting debate and analysis of information. In order
to create an organizational culture of decision legitimacy leaders can do the
following: </p>

<p class="msonormal9">23.14.4.1. Provide a process road map at the beginning of
the decision process. </p>

<p class="msonormal9">23.14.4.2. Reinforce and demonstrate an open mind-set. </p>

<p class="msonormal9">23.14.4.3. Engage in active listening and make sure others
do too. </p>

<p class="msonormal9">23.14.4.4. Separate advocacy from analysis. </p>

<p class="msonormal19">23.14.4.5. Explain the decision rationale once made. </p>

<p class="msonormal9">23.14.4.6. Express appreciation for everyone’s
participation and how alternative inputs contributed to the process. </p>

<p class="msonormal16">23.14.5.<b class="calibre1"> Normal Accidents and Normalizing Deviance. </b></p>

<p class="msonormal9">Within the United States Air Force, like any other
organization decisions made in highly complex tightly integrated environments
often have unanticipated consequence. If Airmen are unaware of, or have failed
to think through decisions catastrophic failure can be the result. With the
understanding of the role all Airmen play in using the habits of mind for
critical thinking provided above, the following sections examine two perspectives
on decision-making failure—one structural; the other behavioral (Normal
Accident Theory, Normalized Deviance).<b class="calibre1"> </b></p>

<p class="msonormal16">23.14.6.<b class="calibre1"> Normal Accident Theory: </b></p>

<p class="msonormal9">23.14.6.1. This theory rests upon the assumption that in
any highly complex high-risk organizational structure decision failures are
unavoidable. High-risk systems are systems classified by their complexity and
the coupling of multiple processes occurring in conjunction with one another.
Systems that are interactively complex and tightly coupled are particularly
vulnerable to catastrophic failure stemming from mistakes made by decision
makers, often small mistakes, which go unrecognized or uncorrected and
increasingly skew outcomes as they work their way through the system. </p>

<p class="msonormal9">23.14.6.2. In coupled systems tight interactions based on
poor decisions can magnify normal accidents into system-wide failure. In simple
linear processes, such as an assembly line, failure has a visible impact on the
next process but is identifiable and limited. When interactions are nonlinear
and affect a variety of other systems, the failure of one component has
unanticipated effects on many subsystems. If the subsystems are tightly coupled
(highly interdependent) a failure quickly causes changes in multiple systems
nearly simultaneously making it hard for leaders to diagnose the symptoms and
see the extent of the developing failure. Because Airmen project power
globally, anticipation of the impact even minor deviations from procedure or
instruction can have is extremely challenging. This is the reason we stress
adherence to standard operating procedures and Airmen must apply the habits of
critical thinking before deviation from our normal operations – others are
counting on our predictability to do their job safely as we work together to advance
United States security interests. </p>

<p class="msonormal16">23.14.7.<b class="calibre1"> Normalizing Deviance: </b></p>

<p class="msonormal9">23.14.7.1. This is the gradual acceptance of unexpected
events and risk as a normal part of the operating environment. Eventually the
deviations are accepted as a normal occurrence and no longer assessed using the
habits of mind necessary to identify causes and find solutions. As
organizational members become accustomed to the reoccurrence of seemingly minor
but unpredicted anomalies in a system they become less concerned with the potential
catastrophic effect of more severe failures of the same systems. The classic
case is the <i class="calibre2">Challenger</i> space shuttle disaster. In this case, the erosion
of O-rings was not within acceptable tolerances. However, after its occurrence
several times with no catastrophic result, the members of the organization
accepted their erosion as a normal and acceptable event, despite deviation from
their engineering standards. In this case National Aeronautics and Space
Administration, as an organization, was working hard to make space flight feel
routine. The organization’s culture, combined with cognitive bias and external
pressures to make space flight routine led do the normalization of a
potentially catastrophic failure. </p>

<p class="msonormal9">23.14.7.2. Normalization of deviance is the gradual
acceptance of lower standards of performance. This practice produces shortcuts
in the way organizations act. These variations then become normal
procedures—normalized to the point where the deviance is no longer even
noticed. As Airmen we should not accept this practice, we guard against this by
continuously questioning the way we do business and digging into any failure to
meet the standards we set for performance.<b class="calibre1"> </b></p>

<p class="msonormal9">23.14.7.3.<b class="calibre1"> </b>Airmen must be aware of the type of
organization they operate within and understand its complex interactions. They
must consciously identify the “close-calls” and deviances from normal
operations. All Airmen must ensure deviations from standards are analyzed as
part of the decision-making process to gain an understanding of how to improve
programs and implement new decisions. </p>

<p class="msonormal16">23.14.8.<b class="calibre1"> Practical Drift and Ambiguity: </b></p>

<p class="msonormal9">23.14.8.1.<b class="calibre1"> Practical Drift.</b><sup class="calibre3"> </sup>Within large
organizations, sub-unit leaders at all levels make decisions to maximize
efficiency. They establish localized rules and procedures that comply with the
overall intent of the organization. Over time these procedures become accepted
practice. Similar to <i class="calibre2">Normalizing Deviance</i> (discussed above), this
practice causes organizational norms to drift. Often, this drift is
unproblematic—however, under ambiguous conditions in complex interactive
environments, divergence may lead to altered expectations and poor information
flow (resulting in catastrophic cross-system failure; e.g. Blackhawk shoot
down). </p>

<p class="msonormal9">23.14.8.2. Airmen must be aware of how their decisions at
the local level tie in with overall organizational goals, standards, and
expectations. Leaders must use their awareness of organizational goals and
standards to monitor <i class="calibre2">practical drift</i> in their areas of responsibility,
recognizing disciplined initiative, while maintaining standards consistent with
outside expectations. This task becomes difficult when many sub-units work
together. Communications breakdowns across large organizations often cause a
loss of perspective on how <i class="calibre2">practical drift</i> may be creating problems with
follow-on unforeseen consequences. </p>

<p class="msonormal9">23.14.8.3. The challenge for Airmen of all ranks is that
ambiguous threats do not trigger organizational responses. The failure to apply
critical thinking to ambiguous threats means that the recovery window between
the emergence of the threat and its occurrence as a catastrophic failure may
narrow. National Aeronautics and Space Administration’s organizational culture
caused leaders to downplay O-ring failure, moving it from a critical to an
ambiguous threat. Airmen at all levels must be aware that ambiguous threats may
go unaddressed due to information filters caused by structural complexity and
inter-organization power dynamics. </p>

<p class="msonormal9">23.14.8.4. Airmen in positions of responsibility must work
to temper <i class="calibre2">practical drift</i> and create a culture where critical thinking
is applied to ambiguous threats. This goal can be accomplished by developing
processes for identifying and analyzing small problems and failures, treating
them as potential indicators of larger problems.  Effective techniques include:
empowerment of front line troops/workers; and flattening hierarchies to reduce
information filtering. </p>

<p class="msonormal9">23.14.8.4.1. To further minimize the problems associated
with <i class="calibre2">practical drift</i>, leaders can also: </p>

<p class="msonormal9">23.14.8.4.2. Create and encourage transparency in
organizational structures and systems to identify local <i class="calibre2">practical drift</i>
and understand the “why” behind local standards. </p>

<p class="msonormal9">23.14.8.4.3. Avoid ‘<i class="calibre2">band-aid’</i> approaches to small
problems – fix the root cause across the system. </p>

<p class="msonormal9">23.14.8.4.4. Create a climate of candid dialogue where you
review and revisit standards and seek problems. </p>

<p class="msonormal9">23.14.8.4.5. Monitor seams where information is handed off
between units and organizations. </p>

<p class="msonormal9">23.14.8.4.6. Conduct careful after-action reviews focused
on process improvement. </p>

<p class="msonormal3"><b class="calibre1">23.15. Conclusion: </b></p>

<p class="msonormal4">23.15.1. Airmen at all levels participate in decision-making
daily. The habits of mind necessary to assure we apply critical thought are
something we must consciously foster. Our diverse and highly educated force
brings to the table a wide variety of views, experiences, and abilities;
providing the United States Air Force a deep pool of talent to draw ideas from.
By using the techniques of good decision-making and fostering the development
of habits of mind in our Airmen we tap into that rich pool of talent. When time
allows we must consciously create processes to think though decisions using
critical analysis of all factors, ensuring we focus on doing what is best for
the nation and the Air Force. This effort to create habits of mind pays off
when we must make decisions quickly and under great pressure. During these
times we naturally fall back on the decision-making processes we use every day.
</p>

<p class="msonormal20">23.15.2. In order to create these good habits of mind Airmen
in leadership positions at all levels, from the back shop to the Air Staff,
must create an environment where Airmen are free to exercise critical thought.
We must guard against organizational cultures and leadership styles designed to
simply arrive at a decision and quickly move on. Organizations and leaders
focused on the decision, not the decision-making process tend to stifle
critical analysis of issues and prevent development of good habits of mind;
ultimately causing poor decision-making and negatively affecting the United
States Air Force, the Department of Defense, and our nation. </p>

<p class="msonormal21"><span class="calibre4"> </span></p>

<p class="msonormal22"> </p>

</div>




</body></html>
